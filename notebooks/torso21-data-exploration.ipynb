{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "torso21_data_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TORSO-21 Dataset"
      ],
      "metadata": {
        "id": "69b78d5d-e536-431e-a204-def9fa7f21c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "\r\n",
        "val2class = {0:0, 127:1, 255:2}\r\n",
        "class2names = {0: \"background\", 1:\"lines\", 2:\"fields\"}"
      ],
      "outputs": [],
      "metadata": {
        "id": "20a071f0-2ab0-41ef-a7eb-beddddf14e2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train set"
      ],
      "metadata": {
        "id": "cc374dc4-6612-4b2d-afe0-107de3f1b6e4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import yaml\r\n",
        "\r\n",
        "train_annotations = \"data/reality/train/annotations.yaml\"\r\n",
        "train_data = None\r\n",
        "\r\n",
        "with open(train_annotations, \"r\") as f:\r\n",
        "    train_data = yaml.safe_load(f)\r\n",
        "        \r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "2881c7b5-6aae-44fa-b52e-2c0795d8cfb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import fiftyone as fo\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "train_samples = []\r\n",
        "train_image_folder = \"data/reality/train/images\"\r\n",
        "train_segmentation_folder = \"data/reality/train/segmentations_fix\"\r\n",
        "\r\n",
        "for image_name in tqdm(train_data[\"images\"]):\r\n",
        "    \r\n",
        "    image_path = os.path.join(train_image_folder, image_name)\r\n",
        "    seg_img_path = os.path.join(train_segmentation_folder, image_name[:-4]+\".png\")\r\n",
        "    \r\n",
        "    if not os.path.exists(image_path):\r\n",
        "        print(image_path)\r\n",
        "        continue\r\n",
        "    \r\n",
        "    data = train_data[\"images\"][image_name]\r\n",
        "    metadata = data['metadata']\r\n",
        "    image_metadata = fo.ImageMetadata.build_for(image_path)\r\n",
        "    metadata = {**metadata, **image_metadata.to_dict()}\r\n",
        "    metadata = fo.Metadata.from_dict(metadata)\r\n",
        "\r\n",
        "    # Create Fiftyone sample\r\n",
        "    sample = fo.Sample(\r\n",
        "        filepath=image_path,\r\n",
        "        metadata=metadata,\r\n",
        "        id=data['id'],\r\n",
        "        tags=['train']\r\n",
        "    )\r\n",
        "\r\n",
        "    # dict_keys(['annotations', 'height', 'id', 'metadata', 'width'])\r\n",
        "    detections = []\r\n",
        "    polylines = []\r\n",
        "    keypoints = []\r\n",
        "\r\n",
        "    for ann in data['annotations']:\r\n",
        "\r\n",
        "        if ann['in_image']:\r\n",
        "            \r\n",
        "            # box annotations for ball, obstacle, robot\r\n",
        "            if ann['type'] in ['obstacle', 'robot', 'ball']:\r\n",
        "                for i in range(0, len(ann['vector']), 2):\r\n",
        "                    bbox = ann['vector'][i] + ann['vector'][i+1]\r\n",
        "                    x1, y1, w, h = bbox[0], bbox[1], bbox[2]-bbox[0], bbox[3]-bbox[1]\r\n",
        "                    detections.append(\r\n",
        "                        fo.Detection(\r\n",
        "                        label=ann['type'],\r\n",
        "                        bounding_box=[x1/image_metadata['width'],y1/image_metadata['height'],w/image_metadata['width'],h/image_metadata['height']],\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "                        )\r\n",
        "                    )\r\n",
        "                    \r\n",
        "            # Polygons for goalpost\r\n",
        "            elif ann['type'] in ['goalpost']:\r\n",
        "                points = []\r\n",
        "                for i in range(0, len(ann['vector'])):\r\n",
        "                    p = ann['vector'][i]\r\n",
        "                    p[0] /= image_metadata['width']\r\n",
        "                    p[1] /= image_metadata['height']\r\n",
        "                    points.append(list(p))\r\n",
        "                    \r\n",
        "                # A closed, filled polygon with a label\r\n",
        "                polylines.append(\r\n",
        "                    fo.Polyline(\r\n",
        "                        label=ann['type'],\r\n",
        "                        points=[points],\r\n",
        "                        closed=True,\r\n",
        "                        filled=True,\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "\r\n",
        "                    )\r\n",
        "                )\r\n",
        "                \r\n",
        "            # Two points center (x,y)\r\n",
        "            elif ann['type'] in ['X-Intersection', 'L-Intersection', 'T-Intersection']:\r\n",
        "                points = []\r\n",
        "                for i in range(0, len(ann['vector'])):\r\n",
        "                    p = ann['vector'][i]\r\n",
        "                    p[0] /= image_metadata['width']\r\n",
        "                    p[1] /= image_metadata['height']\r\n",
        "                    points.append(list(p))\r\n",
        "                    \r\n",
        "                keypoints.append(\r\n",
        "                    fo.Keypoint(\r\n",
        "                        label=ann['type'],\r\n",
        "                        points=points,\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "                    )\r\n",
        "                )\r\n",
        "    \r\n",
        "    # Update to sample\r\n",
        "    sample[\"detections\"] = fo.Detections(detections=detections) if len(detections) > 0 else None\r\n",
        "    sample[\"polylines\"] = fo.Polylines(polylines=polylines) if len(polylines) > 0 else None\r\n",
        "    sample[\"keypoints\"] = fo.Keypoints(keypoints=keypoints) if len(keypoints) > 0 else None\r\n",
        "\r\n",
        "    # Create segmentation mask\r\n",
        "    if os.path.exists(seg_img_path):\r\n",
        "\r\n",
        "        seg_image = cv2.imread(seg_img_path)\r\n",
        "        seg_image = cv2.cvtColor(seg_image, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "        for k,v in val2class.items():\r\n",
        "            seg_image[seg_image == k] = v\r\n",
        "            \r\n",
        "        sample[\"segmentation\"] = fo.Segmentation(mask=seg_image)\r\n",
        "    else:\r\n",
        "        if os.path.exists(seg_img_path.replace('segmentations_fix', 'segmentations')):\r\n",
        "            print('found in original dir: ', seg_img_path)\r\n",
        "        else:\r\n",
        "            print('missing: ', seg_img_path)\r\n",
        "    train_samples.append(sample)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8894 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3b6462218f44139911238d0f93fe82b",
              "version_major": 2,
              "version_minor": 0
            }
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "b9e3f2e1-1674-4ad1-b550-930728d7725e",
        "colab": {
          "referenced_widgets": [
            "b3b6462218f44139911238d0f93fe82b"
          ]
        },
        "outputId": "e516e561-0fb3-4502-8ac7-123c66774b96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Set"
      ],
      "metadata": {
        "id": "408befb8-58db-48b5-bc11-f556c0ce3386"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_annotations = \"data/reality/test/annotations.yaml\"\r\n",
        "test_data = None\r\n",
        "\r\n",
        "with open(test_annotations, \"r\") as f:\r\n",
        "    test_data = yaml.safe_load(f)\r\n",
        "\r\n",
        "test_samples = []\r\n",
        "test_image_folder = \"data/reality/test/images\"\r\n",
        "test_segmentation_folder = \"data/reality/test/segmentations_fix\"\r\n",
        "\r\n",
        "for image_name in tqdm(test_data[\"images\"]):\r\n",
        "    \r\n",
        "    image_path = os.path.join(test_image_folder, image_name)\r\n",
        "    seg_img_path = os.path.join(test_segmentation_folder, image_name[:-4]+\".png\")\r\n",
        "    \r\n",
        "    if not os.path.exists(image_path):\r\n",
        "        print(image_path)\r\n",
        "        continue\r\n",
        "    \r\n",
        "    data = test_data[\"images\"][image_name]\r\n",
        "    metadata = data['metadata']\r\n",
        "    image_metadata = fo.ImageMetadata.build_for(image_path)\r\n",
        "    metadata = {**metadata, **image_metadata.to_dict()}\r\n",
        "    metadata = fo.Metadata.from_dict(metadata)\r\n",
        "    \r\n",
        "    # Create Fiftyone sample\r\n",
        "    sample = fo.Sample(\r\n",
        "        filepath=image_path,\r\n",
        "        metadata=metadata,\r\n",
        "        id=data['id'],\r\n",
        "        tags=['test']\r\n",
        "    )\r\n",
        "\r\n",
        "    # dict_keys(['annotations', 'height', 'id', 'metadata', 'width'])\r\n",
        "    detections = []\r\n",
        "    polylines = []\r\n",
        "    keypoints = []\r\n",
        "\r\n",
        "    for ann in data['annotations']:\r\n",
        "\r\n",
        "        if ann['in_image']:\r\n",
        "            \r\n",
        "            # box annotations for ball, obstacle, robot\r\n",
        "            if ann['type'] in ['obstacle', 'robot', 'ball']:\r\n",
        "                for i in range(0, len(ann['vector']), 2):\r\n",
        "                    bbox = ann['vector'][i] + ann['vector'][i+1]\r\n",
        "                    x1, y1, w, h = bbox[0], bbox[1], bbox[2]-bbox[0], bbox[3]-bbox[1]\r\n",
        "                    detections.append(\r\n",
        "                        fo.Detection(\r\n",
        "                        label=ann['type'],\r\n",
        "                        bounding_box=[x1/image_metadata['width'],y1/image_metadata['height'],w/image_metadata['width'],h/image_metadata['height']],\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "                        )\r\n",
        "                    )\r\n",
        "                    \r\n",
        "            # Polygons for goalpost\r\n",
        "            # TODO: Fix wrong value in FO\r\n",
        "            elif ann['type'] in ['goalpost']:\r\n",
        "                points = []\r\n",
        "                for i in range(0, len(ann['vector'])):\r\n",
        "                    p = ann['vector'][i]\r\n",
        "                    p[0] /= image_metadata['width']\r\n",
        "                    p[1] /= image_metadata['height']\r\n",
        "                    points.append(list(p))\r\n",
        "                    \r\n",
        "                # A closed, filled polygon with a label\r\n",
        "                polylines.append(\r\n",
        "                    fo.Polyline(\r\n",
        "                        label=ann['type'],\r\n",
        "                        points=[points],\r\n",
        "                        closed=True,\r\n",
        "                        filled=True,\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "\r\n",
        "                    )\r\n",
        "                )\r\n",
        "                \r\n",
        "            # Two points center (x,y)\r\n",
        "            # TODO: Fix wrong value in FO\r\n",
        "            elif ann['type'] in ['X-Intersection', 'L-Intersection', 'T-Intersection']:\r\n",
        "                points = []\r\n",
        "                for i in range(0, len(ann['vector'])):\r\n",
        "                    p = ann['vector'][i]\r\n",
        "                    p[0] /= image_metadata['width']\r\n",
        "                    p[1] /= image_metadata['height']\r\n",
        "                    points.append(list(p))\r\n",
        "                    \r\n",
        "                keypoints.append(\r\n",
        "                    fo.Keypoint(\r\n",
        "                        label=ann['type'],\r\n",
        "                        points=points,\r\n",
        "                        blurred=ann['blurred'],\r\n",
        "                        concealed=ann['concealed'],\r\n",
        "                    )\r\n",
        "                )\r\n",
        "    \r\n",
        "    # Update to sample\r\n",
        "    sample[\"detections\"] = fo.Detections(detections=detections) if len(detections) > 0 else None\r\n",
        "    sample[\"polylines\"] = fo.Polylines(polylines=polylines) if len(polylines) > 0 else None\r\n",
        "    sample[\"keypoints\"] = fo.Keypoints(keypoints=keypoints) if len(keypoints) > 0 else None\r\n",
        "\r\n",
        "    # Create segmentation mask\r\n",
        "    if os.path.exists(seg_img_path):\r\n",
        "\r\n",
        "        seg_image = cv2.imread(seg_img_path)\r\n",
        "        seg_image = cv2.cvtColor(seg_image, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "        for k,v in val2class.items():\r\n",
        "            seg_image[seg_image == k] = v\r\n",
        "            \r\n",
        "        sample[\"segmentation\"] = fo.Segmentation(mask=seg_image)\r\n",
        "    else:\r\n",
        "        if os.path.exists(seg_img_path.replace('segmentations_fix', 'segmentations')):\r\n",
        "            print('found in original dir: ', seg_img_path)\r\n",
        "        else:\r\n",
        "            print('missing: ', seg_img_path)\r\n",
        "    test_samples.append(sample)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1570 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e79e94c92f6477f8720493514421c3f",
              "version_major": 2,
              "version_minor": 0
            }
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "f4ba4caf-4d86-4fa6-839d-580ee7d545e5",
        "colab": {
          "referenced_widgets": [
            "4e79e94c92f6477f8720493514421c3f"
          ]
        },
        "outputId": "e4968533-6d4c-4eae-d1b2-5d6c620c3758"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Fiftyone Dataset"
      ],
      "metadata": {
        "id": "291b76e6-23b6-46da-ada0-9e9dd5a1a331"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import fiftyone as fo\r\n",
        "\r\n",
        "# Create an empty dataset\r\n",
        "dataset = fo.Dataset(\"torso_21_dataset\", overwrite=True)\r\n",
        "\r\n",
        "# Store a class list in the dataset's info\r\n",
        "dataset.classes = {\r\n",
        "    \"object_detections\": ['obstacle', 'robot', 'ball'],\r\n",
        "    \"polylines\": [\"goalpost\"],\r\n",
        "    \"keypoints\": ['X-Intersection', 'L-Intersection', 'T-Intersection'],\r\n",
        "}\r\n",
        "\r\n",
        "dataset.mask_targets = {\r\n",
        "    \"ground_truth\": {1:\"lines\", 2:\"fields\"},\r\n",
        "}\r\n",
        "    \r\n",
        "print(dataset)\r\n",
        "dataset.add_samples(train_samples)\r\n",
        "dataset.add_samples(test_samples)\r\n",
        "\r\n",
        "# Export the dataset\r\n",
        "dataset.export(\r\n",
        "    export_dir=\"./torso_21_dataset\",\r\n",
        "    dataset_type=fo.types.FiftyOneImageDetectionDataset,\r\n",
        "    export_media=\"symlink\"\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "d1022750-f142-450e-b9ba-1b27348c2a16",
        "outputId": "77864ef8-d25f-4b08-f300-7f00f69c4c7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preview with FiftyOne"
      ],
      "metadata": {
        "id": "1105faf7-58de-427b-8aef-6e0e99213c9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "session = fo.launch_app(dataset)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8c6ec1f0d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?notebook=true&handleId=0f524721-daa3-423e-a528-52fe0f9ffc9e\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "tags": [],
        "id": "a5959329-0392-41df-a3bb-577ab6fd5416",
        "outputId": "6dd35ac9-05d8-4204-a978-7ce5896b6549"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "b8ea36ee-54e5-4a3f-8f25-8483c51cb244"
      }
    }
  ]
}